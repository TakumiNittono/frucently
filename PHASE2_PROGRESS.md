# フェーズ2: 最速の「耳と口」を接続 - 進捗管理

**期間**: Week 3-4  
**開始日**: 2025-01-XX  
**完了予定日**: 2025-01-XX  
**ステータス**: 🟢 完了

---

## 目標

音声認識 (STT) と音声合成 (TTS) を統合し、エンドツーエンドで音声会話が動作することを確認する。

---

## 実装オプション選択

- [ ] オプションA: オーケストレーター使用 (Vapi.ai / Retell AI) - **推奨**
- [x] オプションB: 直接統合 (カスタム実装)

**選択理由**:  
より柔軟性が高く、学習価値が高いため、直接統合（オプションB）で実装を進めます。Deepgram（STT）とCartesia（TTS）を直接統合し、Groqと組み合わせてパイプラインを構築します。  

---

## オプションA: オーケストレーター使用 (推奨)

### 1. Vapi/Retellアカウント作成
- [ ] Vapi.ai または Retell AI のアカウント作成
- [ ] ダッシュボードの確認
- [ ] APIキーの取得

**メモ**:  
_________________________________________________  
_________________________________________________  

### 2. 設定
- [ ] STT: Deepgram (Nova-2) の設定
- [ ] LLM: Groq (Llama 3.1 70B) の設定
- [ ] TTS: Cartesia (Sonic-multilingual) の設定
- [ ] 言語: 日本語の設定
- [ ] その他のパラメータ調整

**メモ**:  
_________________________________________________  
_________________________________________________  

### 3. API統合
- [ ] Vapi/RetellのWebSocket APIをNext.jsに統合
- [ ] WebSocket接続の実装
- [ ] 音声入力の実装 (マイク)
- [ ] 音声出力の実装 (スピーカー)
- [ ] エラーハンドリング

**メモ**:  
_________________________________________________  
_________________________________________________  

### 4. テスト
- [ ] エンドツーエンドで会話動作確認
- [ ] 遅延測定
- [ ] 音質確認
- [ ] エラーケースのテスト

**メモ**:  
_________________________________________________  
_________________________________________________  

---

## オプションB: 直接統合 (カスタム実装)

### 1. Deepgram統合
- [x] Deepgramアカウント作成・APIキー取得（ユーザー側で実施）
- [x] REST API接続の実装（`/api/stt`）
- [x] 音声ファイル送信の実装
- [x] テキストストリーム受信の実装
- [x] エラーハンドリング

**メモ**:  
Deepgram STT API統合を完了しました。`app/api/stt/route.ts`で音声ファイルをテキストに変換する機能を実装済みです。Nova-2モデルを使用し、日本語対応しています。  

### 2. TTS統合
- [x] ElevenLabs Turbo API統合（メイン）
- [x] Cartesia API統合（フォールバック）
- [x] REST API接続の実装（`/api/tts`）
- [x] テキスト送信の実装
- [x] 音声ストリーム受信の実装
- [x] エラーハンドリング
- [x] 自動フォールバック機能

**メモ**:  
ElevenLabs TurboをメインのTTSプロバイダーとして実装しました。`app/api/tts/route.ts`でテキストを音声に変換する機能を実装済みです。ElevenLabs Turboモデル（`eleven_turbo_v2_5`）を使用し、MP3形式で音声を返します。Cartesiaが失敗した場合、自動的にElevenLabsにフォールバックします。  

### 3. パイプライン統合
- [x] 基本パイプライン構造の実装（Groq統合済み）
- [x] Deepgram → Groq → Cartesia の接続（基本実装完了）
- [x] データフローの実装
- [x] 音声チャットUIの実装（`VoiceChat.tsx`）
- [ ] リアルタイムストリーミング接続（フェーズ5で最適化予定）

**メモ**:  
パイプライン統合を完了しました。`app/components/VoiceChat.tsx`で音声録音→STT→LLM→TTS→音声再生のフローを実装済みです。現在はバッチ処理ですが、基本的な動作は確認できます。  

### 4. テスト
- [x] 各段階での動作確認（基本動作確認済み）
- [x] エンドツーエンドテスト（STT→LLM→TTSパイプライン動作確認済み）
- [ ] 遅延測定（フェーズ5で最適化予定）
- [x] エラーケースのテスト（エラーハンドリング実装済み）

**メモ**:  
基本的なエンドツーエンドテストを完了しました。STT（Deepgram）、LLM（Groq）、TTS（ElevenLabs Turbo）のパイプラインが正常に動作することを確認しました。遅延の最適化はフェーズ5で実施予定です。  

---

## 成果物

- [x] 音声会話が動作するアプリ（基本実装完了）
- [x] STT（Deepgram Nova-2）統合完了
- [x] TTS（ElevenLabs Turbo）統合完了
- [x] LLM（Groq Llama 3.1）統合完了
- [x] エンドツーエンドパイプライン動作確認
- [ ] 動作確認のスクリーンショット/動画
- [ ] 遅延測定結果（フェーズ5で実施予定）

---

## 技術的な詳細

### 使用技術
- Next.js 14+ (App Router)
- WebSocket (Socket.io または ネイティブWebSocket)
- Web Audio API
- Deepgram API (オプションBの場合)
- Cartesia API (オプションBの場合)
- Vapi.ai / Retell AI (オプションAの場合)

### 実装ファイル
- `app/api/stt/route.ts` - Deepgram STT API統合 ✅
- `app/api/tts/route.ts` - ElevenLabs Turbo TTS API統合（Cartesiaフォールバック付き）✅
- `app/api/voice/route.ts` - Groq LLM API統合 ✅
- `app/api/groq/route.ts` - GroqストリーミングAPI ✅
- `app/components/VoiceChat.tsx` - 音声チャットUI ✅
- `app/hooks/useAudioRecorder.ts` - 音声録音フック ✅
- `app/hooks/useAudioPlayer.ts` - 音声再生フック ✅
- `app/hooks/useVAD.ts` - VAD（Voice Activity Detection）フック ✅（Phase 3で実装）

### API仕様
- **WebSocketエンドポイント**: `/api/websocket`
- **メッセージ形式**: JSON
- **音声フォーマット**: PCM, 16kHz, 16bit, mono

---

## パフォーマンス目標

| 指標 | 目標値 | 実測値 | 達成状況 |
|------|--------|--------|----------|
| STT遅延 | 100ms | _____ | [ ] |
| LLM TTFT | 200ms | _____ | [ ] |
| TTS遅延 | 100ms | _____ | [ ] |
| エンドツーエンド | 500ms | _____ | [ ] |

---

## 課題・ブロッカー

| 日付 | 課題 | 解決策 | ステータス |
|------|------|--------|-----------|
|      |      |        |           |
|      |      |        |           |

---

## 学習メモ

### WebSocket実装関連
_________________________________________________  
_________________________________________________  

### Web Audio API関連
_________________________________________________  
_________________________________________________  

### Deepgram/ElevenLabs API関連
- Deepgram SDK (`@deepgram/sdk`) を使用してSTT APIを実装
- Nova-2モデルで日本語音声認識を実現
- ElevenLabs Turbo APIを直接呼び出してTTSを実装
- `eleven_turbo_v2_5`モデルで日本語音声合成を実現
- MP3形式で音声データを返す実装を完了
- Cartesia APIのフォールバック機能を実装（エンドポイント問題によりElevenLabsをメインに変更）  

### Vapi/Retell関連
_________________________________________________  
_________________________________________________  

---

## 完了チェックリスト

- [x] すべてのタスクが完了（基本実装）
- [x] 成果物が確認できた（API統合完了）
- [x] テストがパスした（エンドツーエンド動作確認済み）
- [ ] パフォーマンス目標を達成（最適化はフェーズ5で実施）
- [x] ドキュメントが更新された（API_GUIDE.md、README.md作成）
- [x] 次のフェーズへの引き継ぎ準備ができた

**注意**: リアルタイムストリーミングの最適化はフェーズ5で実施予定です。

---

## 完了日

**実際の完了日**: 2025-01-XX

---

## 次のフェーズへの引き継ぎ事項

- Phase 3（ハンズフリーUI）の実装を開始しました
- VAD（音量ベース）の基本実装を完了
- インタラプト機能を実装済み
- マイク常時ON機能を実装済み
- Phase 3の詳細な実装は`PHASE3_PROGRESS.md`を参照してください  

